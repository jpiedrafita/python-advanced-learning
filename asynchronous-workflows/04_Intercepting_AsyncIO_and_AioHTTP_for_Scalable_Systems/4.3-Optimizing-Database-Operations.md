# 4.3 Optimizing Database Operations
## Async Database Drivers

- PostgreSQL Use asyncpg
- MySQL Use aiomysql
- SQLite Use aiosqlite
- Redis Use aioredis
- MongoDB Use motor

## Why Implement Connection Pool?

- Manage lifecycle
- Reduced latency
- Better scalability

## Implementing a PostgreSQL Connection Pool

(Explica el ejemplo siguiendo el guion de la transcripcion)

```python
# Create the connection pool on application startup
async def init_pg_pool(app):
    app['pg_pool'] = await asyncpg.create_pool(
        dsn='postgresql://user:pass@server:port/db',
        min_size=5,
        max_size=10
    )

# Close the connection pool on application shutdown
async def close_pg_pool(app):
    await app['pg_pool'].close()

# Create the aiohttp application instance
app = web.Application()

# Register the startup and cleanup callbacks
app.on_startup.append(init_pg_pool)
app.on_cleanup.append(close_pg_pool)
```

## Demo: Efficient Database Operations

> **Demo File**: [`demo/db_aiohttp_server.py`](demo/db_aiohttp_server.py)

Let's implement a practical demonstration of efficient database operations using PostgreSQL with connection pooling to replace the in-memory storage used in previous demos.

### Database Setup and Installation

First, install the async database driver for PostgreSQL:

```bash
pip install asyncpg
```

The demo machine has a locally running PostgreSQL server with a new database called `names_db`, with connection details stored in the DSN constant:

```python
DB_DSN = "postgresql://userdb:user@localhost:5432/names_db"
```

### Database Schema Initialization

The `init_db_schema` coroutine handles database initialization, including populating it with initial entries:

```python
async def init_db_schema():
    conn = await asyncpg.connect(DB_DSN)

    await conn.execute(
        """
        CREATE TABLE IF NOT EXISTS names (
            id SERIAL PRIMARY KEY,
            name TEXT NOT NULL
        )
    """
    )

    count = await conn.fetchval("SELECT COUNT(*) FROM names")
    if count == 0:
        await conn.execute(
            "INSERT INTO names (name) VALUES ($1), ($2)", "Sophia", "Michael"
        )

    await conn.close()
```

**Key Features**:
- **One-time Execution**: Since this code runs once at startup, no connection pooling is needed
- **Direct Connection**: Uses `asyncpg.connect()` for simple database setup operations
- **Table Creation**: Creates the `names` table with just two columns for simplicity (ID and name)
- **Initial Data**: Populates the table with "Sophia" and "Michael" if empty
- **Resource Cleanup**: Always closes the connection to free resources

### Connection Pool Implementation

The `init_db_pool` coroutine creates an optimized connection pool:

```python
async def init_db_pool():
    pool = await asyncpg.create_pool(
        dsn=DB_DSN,
        min_size=5,
        max_size=20,
        max_inactive_connection_lifetime=300,
    )

    return pool
```

**Connection Pool Configuration**:
- **Minimum Size (5)**: Maintains at least 5 open connections even when idle, providing baseline capacity for handling requests without connection establishment overhead
- **Maximum Size (20)**: Creates maximum 20 concurrent database connections, preventing database server overload
- **Connection Lifetime (300s)**: Closes inactive connections after 5 minutes to free up resources
- **Performance Optimization**: Avoids the overhead of creating and tearing down connections for each request

### Database Handler Implementation

All previous handlers are rewritten to use the database with connection pooling:

#### Get All Names Handler

```python
async def get_names(request):
    async with request.app["db_pool"].acquire() as conn:
        rows = await conn.fetch("SELECT id, name FROM names ORDER BY id")
        result = {row["id"]: row["name"] for row in rows}
        return web.json_response(result)
```

**Optimization Features**:
- **Connection Acquisition**: Uses `request.app["db_pool"].acquire()` instead of creating new connections
- **Context Manager**: Automatic connection return to pool after use
- **Structured Query**: Returns data in the same format as previous in-memory version

#### Get Name by ID Handler

```python
async def get_name_by_id(request):
    name_id = int(request.match_info.get("id"))
    async with request.app["db_pool"].acquire() as conn:
        row = await conn.fetchrow(
            "SELECT id, name FROM names WHERE id = $1",
            name_id,
        )
        if not row:
            return web.json_response(
                {"error": "Name not found"},
                status=404,
            )
        response = {
            "id": row["id"],
            "name": row["name"],
        }
    return web.json_response(response)
```

**Enhanced Features**:
- **Parameterized Query**: Uses `$1` placeholder for SQL injection prevention
- **Error Handling**: Returns 404 when name not found
- **Pool Reuse**: Acquires existing connection from pool for efficiency

#### Add Name Handler

```python
async def add_name(request):
    data = await request.json()
    name = data.get("name")

    async with request.app["db_pool"].acquire() as conn:
        new_id = await conn.fetchval(
            "INSERT INTO names (name) VALUES ($1) RETURNING id", name
        )

    return web.json_response({"id": new_id, "name": name})
```

**Database Integration**:
- **Insert Query**: Uses PostgreSQL's `RETURNING` clause to get the new ID
- **Single Operation**: Combines insert and ID retrieval in one database call
- **Connection Efficiency**: Leverages pool for quick connection access

### Application Lifecycle Management

The application properly manages database resources throughout its lifecycle:

```python
async def on_startup(app):
    await init_db_schema()
    app["db_pool"] = await init_db_pool()

async def on_cleanup(app):
    if app["db_pool"]:
        await app["db_pool"].close()

async def create_app():
    app = web.Application()

    app.on_startup.append(on_startup)
    app.on_cleanup.append(on_cleanup)

    app.router.add_get("/names", get_names)
    app.router.add_get("/names/{id}", get_name_by_id)
    app.router.add_post("/names", add_name)
    app.router.add_get("/events", sse_handler)

    return app
```

**Lifecycle Features**:
- **Startup**: `on_startup` initializes schema and creates connection pool
- **Cleanup**: `on_cleanup` properly closes all connections when shutting down
- **Flexibility**: Code can run directly or as a Gunicorn worker

### Testing the Database Integration

Start the new server with the database-enabled file:

```bash
gunicorn db_aiohttp_server:create_app --bind localhost:8080 --worker-class aiohttp.GunicornWebWorker --workers 2
```

#### Test Getting All Names

```bash
curl http://localhost:8080/names
```

**Expected Response**:
```json
{
  "1": "Sophia",
  "2": "Michael"
}
```

The response shows Sophia and Michael, read directly from the PostgreSQL database.

#### Test Adding a New Name

```bash
curl -X POST http://localhost:8080/names \
  -H "Content-Type: application/json" \
  -d '{"name": "Alice"}'
```

**Expected Response**:
```json
{
  "id": 3,
  "name": "Alice"
}
```

#### Verify the Addition

```bash
curl http://localhost:8080/names
```

**Expected Response**:
```json
{
  "1": "Sophia",
  "2": "Michael",
  "3": "Alice"
}
```

This confirms the operation was successful and the new name persists in the database.

### Performance Benefits Demonstrated

| Aspect | In-Memory Storage | Database with Pool | Improvement |
|--------|------------------|-------------------|-------------|
| **Data Persistence** | Lost on restart | Persistent | ✅ Data durability |
| **Connection Overhead** | N/A | Eliminated by pooling | ✅ Reduced latency |
| **Scalability** | Memory limited | Database scalable | ✅ Better capacity |
| **Concurrent Access** | Single process | Multi-process safe | ✅ True concurrency |
| **Resource Management** | Automatic | Pool-managed | ✅ Optimized usage |

### Key Optimizations Achieved

1. **Async Database Operations**: Non-blocking database queries using `asyncpg`
2. **Connection Pooling**: Reuse of database connections eliminates setup overhead
3. **Resource Management**: Proper connection lifecycle management
4. **Parameterized Queries**: SQL injection prevention with safe parameter binding
5. **Error Handling**: Graceful handling of database errors and missing records

This demo successfully demonstrates how to connect to a real database and optimize it for performance and scalability with the help of connection pooling, transforming a simple in-memory application into a production-ready database-backed system.





